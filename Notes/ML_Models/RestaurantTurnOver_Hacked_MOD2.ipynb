{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORLA2GE+pjNQ1j0BqU7X1+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/r-autowired/AIMLWorks/blob/main/Notes/ML_Models/RestaurantTurnOver_Hacked_MOD2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WLqSXzsxvPNG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Libraries to help with data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set()\n",
        "\n",
        "# Removes the limit for the number of displayed columns\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "# Sets the limit for the number of displayed rows\n",
        "pd.set_option(\"display.max_rows\", 300)\n",
        "\n",
        "# to split the data into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# to build linear regression_model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# to check model performance\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# to suppress warnings\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgsHqGnqvTkz",
        "outputId": "26e93987-1e7e-4073-922b-ff13862e62e1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/AIML_UT/Colab_Files/Pi2_ML/W1_Linear/Hacky/Train_dataset.csv\")"
      ],
      "metadata": {
        "id": "IXjAqCfmvdV9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "city_corrections = {\n",
        "    'bengaluru': 'bangalore',\n",
        "    'banglore': 'bangalore',\n",
        "    'gandhi nagar': 'gandhinagar',\n",
        "    'navi mumbai': 'mumbai',\n",
        "    'new delhi': 'delhi',\n",
        "    'greater noida': 'noida',\n",
        "    'ncr':'noida',\n",
        "    'nouda':'noida',\n",
        "    'pondi': 'pondicherry',\n",
        "    'pondy': 'pondicherry',\n",
        "    'punr': 'pune',\n",
        "    'siliguri': 'singaruli',\n",
        "    'una': 'unnao',\n",
        "    'trivandrum': 'thiruvananthapuram',\n",
        "    'technopark, trivandrum': 'thiruvananthapuram',\n",
        "    'tirupathi': 'tirupati',\n",
        "    'gurgoan': 'gurgaon',\n",
        "    'kochi/cochin': 'cochin',\n",
        "    'bankura': 'bangalore',\n",
        "    'kochi': 'cochin',\n",
        "    'am': 'ambala',\n",
        "    'bhubaneshwar': 'bhubaneswar',\n",
        "    'bhubneshwar': 'bhubaneswar',\n",
        "    'gajiabaad': 'ghaziabad',\n",
        "    'gaziabaad':\"ghaziabad\",\n",
        "    'gurga':'gurgaon',\n",
        "    'hderabad': 'hyderabad',\n",
        "    'hyderabad(bhadurpally)': 'hyderabad',\n",
        "    'muzzafarpur': 'muzaffarpur',\n",
        "    'indirapuram, ghaziabad': 'ghaziabad',\n",
        "    'nasikcity': 'nashik',\n",
        "    'vizag':'visakhapatnam',\n",
        "    'vsakhapttnam': 'visakhapatnam',\n",
        "    'kolkata`': 'kolkata',\n",
        "    # Add more as needed\n",
        "}\n",
        "\n",
        "# Function to clean city names\n",
        "def clean_cities(city_str, corrections):\n",
        "    if pd.isna(city_str):\n",
        "        return city_str\n",
        "    # Split by comma or ampersand, clean each city, then join back\n",
        "    #cities = [city.strip() for city in city_str.replace('&', ',').split(',')]\n",
        "    #cities = city_str.strip()\n",
        "    corrected_cities = corrections.get(city_str, city_str)\n",
        "    return corrected_cities"
      ],
      "metadata": {
        "id": "wXzn0Q2i7vAe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "df_train = data.copy()\n",
        "df_train['City'] = df_train['City'].fillna('Other')\n",
        "df_train['Cuisine'] = df_train['Cuisine'].fillna('Other')\n",
        "\n",
        "\n",
        "Cuisine_1 =[]\n",
        "Cuisine_2 = []\n",
        "for cus in df_train['Cuisine']:\n",
        "    list_cus = cus.split(',')\n",
        "    Cuisine_1.append(list_cus[0])\n",
        "    Cuisine_2.append(list_cus[1])\n",
        "\n",
        "df_train['Cuisine_1'] = Cuisine_1\n",
        "df_train['Cuisine_2'] = Cuisine_2\n",
        "\n",
        "\n",
        "df_train['Restaurant Theme'] = df_train['Restaurant Theme'].fillna('Other')\n",
        "for col in ['Facebook Popularity Quotient', 'Instagram Popularity Quotient', 'Overall Restaurant Rating', 'Ambience',\n",
        "            'Fire Audit', 'Liquor License Obtained', 'Restaurant Zomato Rating', 'Order Wait Time',\n",
        "            'Staff Responsivness', 'Value for Money', 'Hygiene Rating', 'Food Rating', 'Lively',\n",
        "            'Service', 'Comfortablility', 'Privacy']:\n",
        "    if col in df_train.columns:\n",
        "        df_train[col] = df_train[col].fillna(df_train[col].median())\n",
        "for col in ['Live Music Rating', 'Comedy Gigs Rating']:\n",
        "    if col in df_train.columns:\n",
        "        df_train[col] = df_train[col].fillna(0)\n",
        "        df_train[f'Has_{col.split()[0]}_{col.split()[1]}'] = df_train[col].notna().astype(int)\n",
        "\n",
        "df_train['Opening Day of Restaurant'] = pd.to_datetime(df_train['Opening Day of Restaurant'], errors='coerce')\n",
        "median_date = df_train['Opening Day of Restaurant'].dropna().median()\n",
        "df_train['Opening Day of Restaurant'] = df_train['Opening Day of Restaurant'].fillna(median_date)\n",
        "reference_date = pd.to_datetime('2025-03-29')\n",
        "df_train['Days_Since_Opening'] = (reference_date - df_train['Opening Day of Restaurant']).dt.days.astype(float)\n",
        "df_train = df_train.drop(columns=['Opening Day of Restaurant'])\n",
        "\n",
        "### Making cities names all lower cases\n",
        "df_train['City'] = df_train['City'].str.strip()\n",
        "df_train['City'] = df_train['City'].str.lower()\n",
        "# Clean the 'Cities' column (replace 'Cities' with your actual column name)\n",
        "df_train['City'] = df_train['City'].apply(lambda x: clean_cities(x, city_corrections))\n",
        "\n",
        "#df_train['Opening Day of Restaurant'] = pd.to_datetime(df_train['Opening Day of Restaurant'], errors='coerce').fillna(df_train['Opening Day of Restaurant'].dropna().median())\n",
        "#df_train['Days_Since_Opening'] = (pd.to_datetime('2025-03-29') - df_train['Opening Day of Restaurant']).dt.days.astype(float)\n",
        "\n",
        "# Derived features\n",
        "df_train['Overall_Rating_Squared'] = df_train['Overall Restaurant Rating'] ** 2\n",
        "df_train['Ambience_Squared'] = df_train['Ambience'] ** 2\n",
        "df_train['Social_Media_Interaction'] = df_train['Facebook Popularity Quotient'] * df_train['Instagram Popularity Quotient']\n",
        "df_train['Entertainment_Score'] = df_train['Live Music Rating'] + df_train['Comedy Gigs Rating']\n",
        "\n",
        "\n",
        "df_train.drop(['Live Music Rating'], axis=1, inplace=True)\n",
        "df_train.drop(['Comedy Gigs Rating'], axis=1, inplace=True)\n",
        "df_train.drop(['Value Deals Rating'], axis=1, inplace=True)\n",
        "df_train.drop(['Registration Number'], axis=1, inplace=True)\n",
        "df_train.drop(['Resturant Tier'], axis=1, inplace=True)\n",
        "df_train.drop(['Live Sports Rating'], axis=1, inplace=True)\n",
        "df_train.drop(['Facebook Popularity Quotient', 'Instagram Popularity Quotient'], axis=1, inplace=True)\n",
        "df_train.drop(['Overall Restaurant Rating', 'Ambience'], axis=1, inplace=True)\n",
        "df_train.drop(['Cuisine'], axis=1, inplace=True)\n",
        "#df_train.drop(['Has_Live_Music', 'Has_Comedy_Gigs'], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "# New numeric columns (assuming present)\n",
        "for col in ['Fire Audit', 'Liquor License Obtained', 'Restaurant Zomato Rating', 'Order Wait Time', 'Staff Responsivness', 'Value for Money', 'Hygiene Rating', 'Food Rating', 'Lively', 'Service', 'Comfortablility', 'Privacy']:\n",
        "    if col in df_train.columns:\n",
        "        df_train[col] = df_train[col].fillna(df_train[col].median())\n",
        "threshold = 20\n",
        "for col in ['City', 'Cuisine_1', 'Cuisine_2', 'Restaurant Theme']:\n",
        "    counts = df_train[col].value_counts()\n",
        "    rare = counts[counts < threshold].index\n",
        "    df_train[col] = df_train[col].replace(rare, 'Other_' + col)\n",
        "\n",
        "# One-hot encode\n",
        "df_train = pd.get_dummies(df_train, columns=['City', 'Cuisine_1', 'Cuisine_2', 'Restaurant Theme', 'Restaurant Type', 'Endorsed By', 'Restaurant Location'],\n",
        "                          prefix=['City', 'Cuisine_1', 'Cuisine_2', 'Theme', 'Type', 'Endorsed', 'Location'], drop_first=True)\n",
        "\n",
        "# Drop 'Restaurant ID'\n",
        "if 'Restaurant ID' in df_train.columns:\n",
        "    df_train = df_train.drop(columns=['Restaurant ID'])\n",
        "\n",
        "# Log-transform target\n",
        "df_train['Log_Annual_Turnover'] = np.log1p(df_train['Annual Turnover'])\n",
        "\n",
        "# Features and target\n",
        "X = df_train.drop(columns=['Annual Turnover', 'Log_Annual_Turnover', 'Opening Day of Restaurant'], errors='ignore')\n",
        "y = df_train['Log_Annual_Turnover']\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Step 2: Train Random Forest ---\n",
        "rf_model = RandomForestRegressor(n_estimators=200, max_depth=15, min_samples_split=10, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_train_pred = np.expm1(rf_model.predict(X_train))\n",
        "y_test_pred = np.expm1(rf_model.predict(X_test))\n",
        "train_rmse = np.sqrt(mean_squared_error(np.expm1(y_train), y_train_pred))\n",
        "test_rmse = np.sqrt(mean_squared_error(np.expm1(y_test), y_test_pred))\n",
        "train_r2 = r2_score(np.expm1(y_train), y_train_pred)\n",
        "test_r2 = r2_score(np.expm1(y_test), y_test_pred)\n",
        "\n",
        "print(f\"Random Forest - Train RMSE: {train_rmse:.2f}\")\n",
        "print(f\"Random Forest - Test RMSE: {test_rmse:.2f}\")\n",
        "print(f\"Random Forest - Train R-squared: {train_r2:.4f}\")\n",
        "print(f\"Random Forest - Test R-squared: {test_r2:.4f}\")\n",
        "\n",
        "# Feature importance\n",
        "importances = rf_model.feature_importances_\n",
        "\n",
        "for name, imp in sorted(zip(X_train.columns, importances), key=lambda x: x[1], reverse=True)[:10]:\n",
        "    print(f\"{name}: {imp:.4f}\")\n",
        "\n",
        "# --- Step 3: Predict on Test Data ---\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/AIML_UT/Colab_Files/Pi2_ML/W1_Linear/Hacky/Test_dataset.csv\")\n",
        "df_test = test_data.copy()\n",
        "# Preprocess test data\n",
        "df_test['City'] = df_test['City'].fillna('Other')\n",
        "df_test['Cuisine'] = df_test['Cuisine'].fillna('Other')\n",
        "\n",
        "test_Cuisine_1 =[]\n",
        "test_Cuisine_2 = []\n",
        "for cus in df_test['Cuisine']:\n",
        "    list_cus1 = cus.split(',')\n",
        "    test_Cuisine_1.append(list_cus1[0])\n",
        "    test_Cuisine_2.append(list_cus1[1])\n",
        "\n",
        "df_test['test_Cuisine_1'] = test_Cuisine_1\n",
        "df_test['test_Cuisine_2'] = test_Cuisine_2\n",
        "\n",
        "\n",
        "df_test['Restaurant Theme'] = df_test['Restaurant Theme'].fillna('Other')\n",
        "for col in ['Facebook Popularity Quotient', 'Instagram Popularity Quotient', 'Overall Restaurant Rating', 'Ambience',\n",
        "            'Fire Audit', 'Liquor License Obtained', 'Restaurant Zomato Rating', 'Order Wait Time',\n",
        "            'Staff Responsivness', 'Value for Money', 'Hygiene Rating', 'Food Rating', 'Lively',\n",
        "            'Service', 'Comfortablility', 'Privacy']:\n",
        "    if col in df_test.columns:\n",
        "        df_test[col] = df_test[col].fillna(df_test[col].median())\n",
        "for col in ['Live Music Rating', 'Comedy Gigs Rating']:\n",
        "    if col in df_test.columns:\n",
        "        df_test[col] = df_test[col].fillna(0)\n",
        "        df_test[f'Has_{col.split()[0]}_{col.split()[1]}'] = df_test[col].notna().astype(int)\n",
        "#df_test['Opening Day of Restaurant'] = pd.to_datetime(df_test['Opening Day of Restaurant'], errors='coerce').fillna(df_train['Opening Day of Restaurant'].dropna().median())\n",
        "#df_test['Opening Day of Restaurant'] = pd.to_datetime(df_test['Opening Day of Restaurant'], errors='coerce')\n",
        "df_test['Opening Day of Restaurant'] = pd.to_datetime(df_test['Opening Day of Restaurant'], errors='coerce')\n",
        "median_date1 = df_test['Opening Day of Restaurant'].dropna().median()\n",
        "df_test['Opening Day of Restaurant'] = df_test['Opening Day of Restaurant'].fillna(median_date1)\n",
        "reference_date1 = pd.to_datetime('2025-03-29')\n",
        "df_test['Days_Since_Opening'] = (reference_date1 - df_test['Opening Day of Restaurant']).dt.days.astype(float)\n",
        "df_test = df_test.drop(columns=['Opening Day of Restaurant'])\n",
        "\n",
        "# Derived features\n",
        "df_test['Overall_Rating_Squared'] = df_test['Overall Restaurant Rating'] ** 2\n",
        "df_test['Ambience_Squared'] = df_test['Ambience'] ** 2\n",
        "df_test['Social_Media_Interaction'] = df_test['Facebook Popularity Quotient'] * df_test['Instagram Popularity Quotient']\n",
        "df_test['Entertainment_Score'] = df_test['Live Music Rating'] + df_test['Comedy Gigs Rating']\n",
        "\n",
        "### Making cities names all lower cases\n",
        "df_test['City'] = df_test['City'].str.strip()\n",
        "df_test['City'] = df_test['City'].str.lower()\n",
        "# Clean the 'Cities' column (replace 'Cities' with your actual column name)\n",
        "df_test['City'] = df_test['City'].apply(lambda x: clean_cities(x, city_corrections))\n",
        "\n",
        "\n",
        "df_test.drop(['Live Music Rating'], axis=1, inplace=True)\n",
        "df_test.drop(['Comedy Gigs Rating'], axis=1, inplace=True)\n",
        "df_test.drop(['Value Deals Rating'], axis=1, inplace=True)\n",
        "df_test.drop(['Registration Number'], axis=1, inplace=True)\n",
        "df_test.drop(['Resturant Tier'], axis=1, inplace=True)\n",
        "df_test.drop(['Live Sports Rating'], axis=1, inplace=True)\n",
        "df_test.drop(['Facebook Popularity Quotient', 'Instagram Popularity Quotient'], axis=1, inplace=True)\n",
        "df_test.drop(['Overall Restaurant Rating', 'Ambience'], axis=1, inplace=True)\n",
        "df_test.drop(['Cuisine'], axis=1, inplace=True)\n",
        "#df_test.drop(['Has_Live_Music', 'Has_Comedy_Gigs'], axis=1, inplace=True)\n",
        "\n",
        "\n",
        "# New numeric columns (assuming present)\n",
        "for col in ['Fire Audit', 'Liquor License Obtained', 'Restaurant Zomato Rating', 'Order Wait Time', 'Staff Responsivness', 'Value for Money', 'Hygiene Rating', 'Food Rating', 'Lively', 'Service', 'Comfortablility', 'Privacy']:\n",
        "    if col in df_test.columns:\n",
        "        df_test[col] = df_test[col].fillna(df_test[col].median())\n",
        "\n",
        "# Group rare categories (use training threshold)\n",
        "for col in ['City', 'test_Cuisine_1', 'test_Cuisine_2', 'Restaurant Theme']:\n",
        "    counts = df_test[col].value_counts()\n",
        "    rare = counts[counts < threshold].index\n",
        "    df_test[col] = df_test[col].apply(lambda x: x if x in counts and counts[x] >= threshold else 'Other_' + col)\n",
        "\n",
        "# One-hot encode and align\n",
        "df_test = pd.get_dummies(df_test, columns=['City','test_Cuisine_1', 'test_Cuisine_2', 'Restaurant Theme', 'Restaurant Type', 'Endoresed By', 'Restaurant Location'],\n",
        "                         prefix=['City', 'test_Cuisine_1', 'test_Cuisine_2', 'Theme', 'Type', 'Endorsed', 'Location'], drop_first=True)\n",
        "missing_cols = set(X_train.columns) - set(df_test.columns)\n",
        "for col in missing_cols:\n",
        "    df_test[col] = 0\n",
        "df_test = df_test[X_train.columns]\n",
        "\n",
        "# Predict\n",
        "predictions = np.expm1(rf_model.predict(df_test))\n",
        "print(\"Sample predictions:\", predictions[:10])\n",
        "print(\"Mean prediction:\", predictions.mean())\n",
        "\n",
        "# Save\n",
        "\n",
        "\n",
        "solution_df = pd.DataFrame(test_data['Registration Number'])\n",
        "solution_df['Annual Turnover'] = predictions\n",
        "solution_df\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/AIML_UT/Colab_Files/Pi2_ML/W1_Linear/Hacky')\n",
        "# Get the current working directory\n",
        "current_dir = os.getcwd()\n",
        "print(\"Current working directory:\", current_dir)\n",
        "solution_df.to_csv('SubmissionMod3.csv',index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZGCeSZz55ie",
        "outputId": "a4737522-e3af-48d2-df56-4f7298addfc2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - Train RMSE: 15390621.25\n",
            "Random Forest - Test RMSE: 19648321.40\n",
            "Random Forest - Train R-squared: 0.4983\n",
            "Random Forest - Test R-squared: 0.1509\n",
            "Days_Since_Opening: 0.1397\n",
            "Hygiene Rating: 0.1377\n",
            "Social_Media_Interaction: 0.1369\n",
            "Service: 0.0333\n",
            "Entertainment_Score: 0.0332\n",
            "Ambience_Squared: 0.0328\n",
            "Comfortablility: 0.0292\n",
            "Order Wait Time: 0.0282\n",
            "Lively: 0.0268\n",
            "Privacy: 0.0244\n",
            "Sample predictions: [24248285.66351976 30604208.08673704 28375324.21075739 47191345.13633797\n",
            " 39978513.0059566  30818611.00789102 35001107.44878983 26035370.09838893\n",
            " 19596022.70696332 22421830.06485058]\n",
            "Mean prediction: 26836990.514901232\n",
            "Current working directory: /content/drive/MyDrive/AIML_UT/Colab_Files/Pi2_ML/W1_Linear/Hacky\n"
          ]
        }
      ]
    }
  ]
}